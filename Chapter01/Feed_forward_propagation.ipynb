{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feed_forward_propagation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzorani/Practical-Data-Science-with-Python/blob/main/Chapter01/Feed_forward_propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk4Fezbb9SZc"
      },
      "source": [
        "# Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T12:46:03.594770Z",
          "start_time": "2020-09-24T12:46:03.589643Z"
        },
        "id": "VytiqjTQgwf4"
      },
      "source": [
        "'''\n",
        "import numpy as np\n",
        "def feed_forward(inputs, outputs, weights):\n",
        "    pre_hidden = np.dot(inputs,weights[0])+ weights[1]\n",
        "    hidden = 1/(1+np.exp(-pre_hidden))\n",
        "    pred_out = np.dot(hidden, weights[2]) + weights[3]\n",
        "    mean_squared_error = np.mean(np.square(pred_out - outputs))\n",
        "    return mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the input variable values, weights, and actual outputs\n",
        "import numpy as np\n",
        "def feed_forward(inputs, outputs, weights):\n",
        "\n",
        "# Calculate hidden layer values by performing the matrix multiplication (np.dot)\n",
        "# of inputs and weight values, connecting the input layer to the hidden layer,\n",
        "# and add the bias terms associated with the hidden layer's nodes\n",
        "    pre_hidden = np.dot(inputs, weights[0]) + weights[1]\n",
        "\n",
        "# Apply the Sigmoid activation function on top of the hidden layer values\n",
        "    hidden = 1 / (1 + np.ext(-pre_hidden))\n",
        "\n",
        "# Calculate the output layer values by performing the matrix multiplication\n",
        "# (np.dot) of hidden layer activation values (hidden) and weights connecting the\n",
        "# hidden layer to the output layer, and assuming the output with bias associated\n",
        "# with the node in the output layer\n",
        "    pred_out = np.dot(hidden, weights[2]) + weights[3]\n",
        "\n",
        "# Calculating the mean squared error value across the dataset, and return the\n",
        "# mean squared error\n",
        "    mean_squared_error = np.mean(np.square(pred_out - outputs))\n",
        "    return mean_squared_error"
      ],
      "metadata": {
        "id": "FrS_jw63qLP-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Activation Functions"
      ],
      "metadata": {
        "id": "_5bpjg53DZdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ahKMXZx-syKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))"
      ],
      "metadata": {
        "id": "jDWEh0oDDtlv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    # If x is greater than zero return x, otherwise return zero\n",
        "    return np.where(x>0, x, 0)"
      ],
      "metadata": {
        "id": "llUDB_PeECwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def liner(x):\n",
        "    return x"
      ],
      "metadata": {
        "id": "j8vS00j2E-gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x))"
      ],
      "metadata": {
        "id": "Ov4UkoxuFPYS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Functions"
      ],
      "metadata": {
        "id": "syekbqz7FtfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mean square error\n",
        "def mse(p, y):\n",
        "    np.mean(np.square(p - y))"
      ],
      "metadata": {
        "id": "CdVM_W-XFvZq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mean absolute error\n",
        "def mae(p, y):\n",
        "    np.mean(np.abs(p - y))"
      ],
      "metadata": {
        "id": "RrLfNoxgHfA4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# binary cross entropy\n",
        "def bce(p, y):\n",
        "    return -np.mean(y * np.log(p) + (1 - y) * np.log(1 - p))"
      ],
      "metadata": {
        "id": "kRFRpy5gHmw4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical cross entropy\n",
        "def cce(p, y):\n",
        "    return -np.mean(np.sum(y * np.log(p), axis=1))"
      ],
      "metadata": {
        "id": "NzKbfmVHH42t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ],
      "metadata": {
        "id": "s767gSEHK7PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing \"deepcopy\" from the \"copy\" library\n",
        "# \"deepcopy\" ensures we can work with multiple copies of weights without\n",
        "# changing the original weight values\n",
        "from copy import deepcopy\n",
        "\n",
        "# Creating three copies from the original set of weights passed as an input to\n",
        "# the function\n",
        "original_weights = deepcopy(weights)\n",
        "temp_weights = deepcopy(weights)\n",
        "updated_weights = deepcopy(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "c_0mg2etIeoS",
        "outputId": "f9e8af2a-b047-49fb-bfd1-711948bbb183"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'weights' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-632d3fca3f76>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# creating three copies from the original set of weights passed as an input to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moriginal_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtemp_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mupdated_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the loss value (original_loss) with the original set of weights,\n",
        "# by passing inputs, outputs, and original_weights through the \"feed_forward\"\n",
        "# function\n",
        "original_loss = feed_forward(inputs, outputs, original_weigths)\n",
        "\n",
        "# Looping through all layers of the network\n",
        "for i, layer in enumerate(original_weights):\n",
        "    # Looping through all the individual parameters\n",
        "    for index, weight in np.ndnumerate(layer):\n",
        "        temp_weights = deepcopy(original_weights) # resetting \"temp_weights\"\n",
        "        temp_weights[i][index] += lr # increasing by the learning rate\n",
        "        _loss_plus = feed_forward(inputs, outputs, temp_weights) # computing the new loss\n",
        "        grad = (_loss_plus - original_loss) / lr # calculating the gradient\n",
        "        updated_weights[i][index] -= grad * lr # updating the weights\n",
        "return updated_weights, original_loss"
      ],
      "metadata": {
        "id": "CdASsI1ACM7Y",
        "outputId": "ed6425de-534c-4fc8-f7fa-d66b2cf42cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4d49802f0d4d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# by passing inputs, outputs, and original_weights through the \"feed_forward\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moriginal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_weigths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# looping through all layers of the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-NUKSggE7og"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}